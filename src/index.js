/**
 * RAG Pipeline Main Entry Point
 * RAGæµæ°´çº¿ä¸»å…¥å£
 */

const config = require('./config/config');
const PipelineOrchestrator = require('./pipeline-orchestrator');
const { getLogger } = require('./services/logger');

class RAGPipeline {
  constructor() {
    this.config = config;
    this.logger = getLogger(this.config);
    this.orchestrator = null;
  }

  /**
   * åˆå§‹åŒ–ç³»ç»Ÿ
   */
  async initialize() {
    try {
      this.logger.info('ğŸš€ Initializing RAG Pipeline System');

      // éªŒè¯é…ç½®
      this.config.validate();

      // åˆå§‹åŒ–ç¼–æ’å™¨
      this.orchestrator = new PipelineOrchestrator(this.config);
      await this.orchestrator.initialize();

      this.logger.info('âœ… RAG Pipeline System initialized successfully');
    } catch (error) {
      this.logger.error('âŒ Failed to initialize RAG Pipeline System', { error: error.message });
      throw error;
    }
  }

  /**
   * æ‰§è¡Œå®Œæ•´æµæ°´çº¿
   */
  async runPipeline(options = {}) {
    try {
      if (!this.orchestrator) {
        await this.initialize();
      }

      this.logger.info('ğŸ¯ Starting RAG Pipeline execution', options);

      const result = await this.orchestrator.executePipeline(options);

      this.logger.info('ğŸ‰ RAG Pipeline execution completed successfully', {
        duration: result.duration,
        totalDocuments: result.overallStats?.totalDocuments || 0
      });

      return result;
    } catch (error) {
      this.logger.error('ğŸ’¥ RAG Pipeline execution failed', { error: error.message });
      throw error;
    }
  }

  /**
   * æ‰§è¡Œå•ä¸ªé˜¶æ®µ
   */
  async runStage(stageName, options = {}) {
    try {
      if (!this.orchestrator) {
        await this.initialize();
      }

      this.logger.info(`ğŸ¯ Executing single stage: ${stageName}`, options);

      const result = await this.orchestrator.executeStage(stageName, options);

      this.logger.info(`âœ… Stage ${stageName} execution completed`, {
        duration: result.duration
      });

      return result;
    } catch (error) {
      this.logger.error(`ğŸ’¥ Stage ${stageName} execution failed`, { error: error.message });
      throw error;
    }
  }

  /**
   * è·å–ç³»ç»ŸçŠ¶æ€
   */
  getStatus() {
    if (!this.orchestrator) {
      return { status: 'not_initialized' };
    }

    return {
      status: 'initialized',
      execution: this.orchestrator.getExecutionStatus(),
      health: null, // å¯ä»¥åç»­å®ç°å¥åº·æ£€æŸ¥
      config: this.orchestrator.getConfiguration()
    };
  }

  /**
   * å¥åº·æ£€æŸ¥
   */
  async healthCheck() {
    try {
      if (!this.orchestrator) {
        return { status: 'not_initialized' };
      }

      const health = await this.orchestrator.healthCheck();
      return health;
    } catch (error) {
      return {
        status: 'unhealthy',
        error: error.message,
        timestamp: new Date().toISOString()
      };
    }
  }

  /**
   * æ¸…ç†èµ„æº
   */
  async cleanup() {
    try {
      if (this.orchestrator) {
        await this.orchestrator.cleanup();
      }
      this.logger.info('ğŸ§¹ RAG Pipeline cleanup completed');
    } catch (error) {
      this.logger.error('âŒ Error during cleanup', { error: error.message });
    }
  }
}

// CLI å…¥å£ç‚¹
async function main() {
  const ragPipeline = new RAGPipeline();

  try {
    // è§£æå‘½ä»¤è¡Œå‚æ•°
    const args = process.argv.slice(2);
    const command = args[0] || 'pipeline';

    switch (command) {
      case 'pipeline':
        // æ‰§è¡Œå®Œæ•´æµæ°´çº¿
        const pipelineOptions = parsePipelineOptions(args.slice(1));
        await ragPipeline.initialize();
        const result = await ragPipeline.runPipeline(pipelineOptions);
        console.log('Pipeline completed successfully:', result.overallStats);
        break;

      case 'clone':
      case 'clean':
      case 'upload':
        // æ‰§è¡Œå•ä¸ªé˜¶æ®µ
        const stageOptions = parseStageOptions(command, args.slice(1));
        await ragPipeline.initialize();
        const stageResult = await ragPipeline.runStage(command, stageOptions);
        console.log(`Stage ${command} completed successfully:`, stageResult.stats);
        break;

      case 'status':
        // è·å–çŠ¶æ€
        const status = ragPipeline.getStatus();
        console.log('System status:', JSON.stringify(status, null, 2));
        break;

      case 'health':
        // å¥åº·æ£€æŸ¥
        await ragPipeline.initialize();
        const health = await ragPipeline.healthCheck();
        console.log('Health check:', JSON.stringify(health, null, 2));
        break;

      default:
        printUsage();
        process.exit(1);
    }
  } catch (error) {
    console.error('Error:', error.message);
    process.exit(1);
  } finally {
    await ragPipeline.cleanup();
  }
}

/**
 * è§£ææµæ°´çº¿é€‰é¡¹
 */
function parsePipelineOptions(args) {
  const options = {};

  for (let i = 0; i < args.length; i++) {
    const arg = args[i];

    switch (arg) {
      case '--folders':
      case '-f':
        options.folderTokens = args[++i]?.split(',');
        break;
      case '--force-full':
        options.forceFullUpdate = true;
        break;
      case '--force-reprocess':
        options.forceReprocess = true;
        break;
      case '--force-reindex':
        options.forceReindex = true;
        break;
      case '--batch-size':
        options.batchSize = parseInt(args[++i]);
        break;
      case '--max-concurrent':
        options.maxConcurrentAiRequests = parseInt(args[++i]);
        break;
      case '--skip-stages':
        options.skipStages = args[++i]?.split(',');
        break;
    }
  }

  return options;
}

/**
 * è§£æé˜¶æ®µé€‰é¡¹
 */
function parseStageOptions(stageName, args) {
  const options = {};

  for (let i = 0; i < args.length; i++) {
    const arg = args[i];

    switch (arg) {
      case '--folders':
      case '-f':
        if (stageName === 'clone') {
          options.folderTokens = args[++i]?.split(',');
        }
        break;
      case '--documents':
        if (['clean', 'upload'].includes(stageName)) {
          options.documents = JSON.parse(args[++i]);
        }
        break;
      case '--batch-size':
        options.batchSize = parseInt(args[++i]);
        break;
      case '--force':
        if (stageName === 'clean') {
          options.forceReprocess = true;
        } else if (stageName === 'upload') {
          options.forceReindex = true;
        }
        break;
    }
  }

  return options;
}

/**
 * æ‰“å°ä½¿ç”¨è¯´æ˜
 */
function printUsage() {
  console.log(`
RAG Pipeline - é£ä¹¦æ–‡æ¡£çŸ¥è¯†åº“æ„å»ºç³»ç»Ÿ

Usage:
  npm start [command] [options]

Commands:
  pipeline    æ‰§è¡Œå®Œæ•´æµæ°´çº¿ (é»˜è®¤)
  clone       æ‰§è¡Œæ–‡æ¡£é‡‡é›†é˜¶æ®µ
  clean       æ‰§è¡Œå†…å®¹å¤„ç†é˜¶æ®µ
  upload      æ‰§è¡Œç´¢å¼•æ„å»ºé˜¶æ®µ
  status      æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
  health      æ‰§è¡Œå¥åº·æ£€æŸ¥

Pipeline Options:
  -f, --folders <tokens>       é£ä¹¦æ–‡ä»¶å¤¹tokens (ç”¨é€—å·åˆ†éš”)
  --force-full                 å¼ºåˆ¶å…¨é‡æ›´æ–°
  --force-reprocess            å¼ºåˆ¶é‡æ–°å¤„ç†AIå†…å®¹
  --force-reindex              å¼ºåˆ¶é‡æ–°ç´¢å¼•
  --batch-size <number>        æ‰¹å¤„ç†å¤§å° (é»˜è®¤: 10)
  --max-concurrent <number>    æœ€å¤§å¹¶å‘AIè¯·æ±‚æ•° (é»˜è®¤: 5)
  --skip-stages <stages>       è·³è¿‡æŒ‡å®šé˜¶æ®µ (ç”¨é€—å·åˆ†éš”)

Stage Options:
  -f, --folders <tokens>       cloneé˜¶æ®µ: æ–‡ä»¶å¤¹tokens
  --documents <json>           clean/uploadé˜¶æ®µ: æ–‡æ¡£æ•°æ®
  --batch-size <number>        æ‰¹å¤„ç†å¤§å°
  --force                      å¼ºåˆ¶é‡æ–°å¤„ç†/ç´¢å¼•

Examples:
  npm start pipeline --folders "folder1,folder2"
  npm start clone --folders "folder1"
  npm start clean --documents '[{"id": "doc1", "content": "..."}]'
  npm start status
  `);
}

// å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œå¯åŠ¨CLI
if (require.main === module) {
  main().catch(error => {
    console.error('Unhandled error:', error);
    process.exit(1);
  });
}

module.exports = RAGPipeline;



